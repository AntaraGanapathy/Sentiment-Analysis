{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680c0a74-a718-454d-b6cf-9cdd6b921776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import load_model\n",
    "import nest_asyncio\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbcfa55-e5ff-474a-ab3b-9ff553295e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   publish_date  1244184 non-null  int64 \n",
      " 1   text          1244184 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('abcnews-date-text.csv')\n",
    "df = df.rename(columns = {'headline_text': 'text'})\n",
    "df['text'] = df['text'].astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca2946b-1385-403e-9074-ffc5ecf432d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    check = string.punctuation\n",
    "    def remove_punctuation(text):\n",
    "        no_punct=[words for words in text if words not in check]\n",
    "        words_wo_punct=''.join(no_punct)\n",
    "        return tokenize(words_wo_punct)\n",
    "    \n",
    "    def tokenize(text):\n",
    "        split=re.split(\"\\W+\",text) \n",
    "        return remove_stopwords(split)\n",
    "\n",
    "    def remove_stopwords(text):\n",
    "        text=[word for word in text if word not in stopword]\n",
    "        return text\n",
    "    return remove_punctuation(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59544bf3-b592-4d99-8fc3-380dac8d7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "\n",
    "for i in df['text']:\n",
    "    cleaned.append(clean_text(i.lower()))\n",
    "\n",
    "df['text'] = cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224f5711-4c46-4ce6-aa07-a55ffd1fa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "\n",
    "def getAnalysis(polarity):\n",
    "        if score < 0:\n",
    "            return 0\n",
    "        elif score > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "            \n",
    "for i in range(len(df['text'])):\n",
    "    text = \" \".join(df['text'][i])\n",
    "    score = TextBlob(text).sentiment.polarity\n",
    "    polarity.append(getAnalysis(score))\n",
    "\n",
    "df['label'] = polarity\n",
    "\n",
    "df.drop(df[df['label'] == -1].index, inplace=True)\n",
    "\n",
    "df.to_csv(\"training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d3df55-8fdc-4f21-bc33-5d2fa097af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training.csv')\n",
    "\n",
    "text = list(data['text'])\n",
    "labels = list(data['label'])\n",
    "\n",
    "training_text = text[0:15000]\n",
    "testing_text = text[15000:]\n",
    "\n",
    "training_labels = labels[0:15000]\n",
    "testing_labels = labels[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb91496f-eb9a-4269-b241-53409e24c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token= \"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_text)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_text)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=120, padding='post', truncating='post')\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_text)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=120, padding='post', truncating='post')\n",
    "\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712ce450-f6e8-4775-b639-f4c280d1e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 21:15:14.885239: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-18 21:15:14.885901: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=120),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b5b556-9d88-4114-9df4-30dd71d8a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 21:15:14.998013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-06-18 21:15:15.000635: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 21:15:15.173416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-18 21:15:19.030573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 - 34s - loss: 0.6767 - accuracy: 0.5818 - val_loss: 0.6731 - val_accuracy: 0.5655\n",
      "Epoch 2/10\n",
      "469/469 - 34s - loss: 0.5754 - accuracy: 0.7036 - val_loss: 0.4685 - val_accuracy: 0.7439\n",
      "Epoch 3/10\n",
      "469/469 - 33s - loss: 0.2688 - accuracy: 0.9357 - val_loss: 0.2440 - val_accuracy: 0.9319\n",
      "Epoch 4/10\n",
      "469/469 - 33s - loss: 0.1363 - accuracy: 0.9668 - val_loss: 0.1862 - val_accuracy: 0.9381\n",
      "Epoch 5/10\n",
      "469/469 - 34s - loss: 0.0890 - accuracy: 0.9776 - val_loss: 0.1517 - val_accuracy: 0.9492\n",
      "Epoch 6/10\n",
      "469/469 - 33s - loss: 0.0640 - accuracy: 0.9839 - val_loss: 0.1337 - val_accuracy: 0.9534\n",
      "Epoch 7/10\n",
      "469/469 - 33s - loss: 0.0483 - accuracy: 0.9873 - val_loss: 0.1265 - val_accuracy: 0.9550\n",
      "Epoch 8/10\n",
      "469/469 - 33s - loss: 0.0375 - accuracy: 0.9905 - val_loss: 0.1187 - val_accuracy: 0.9579\n",
      "Epoch 9/10\n",
      "469/469 - 33s - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.1154 - val_accuracy: 0.9590\n",
      "Epoch 10/10\n",
      "469/469 - 33s - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.1133 - val_accuracy: 0.9597\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(training_padded, \n",
    "                    training_labels, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, testing_labels), \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bc4d97-edb2-439f-a80d-bb8b67d1eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "session = HTMLSession()\n",
    "urls = []\n",
    "\n",
    "r = session.get('https://edition.cnn.com/opinions')\n",
    "    \n",
    "html_str = r.text\n",
    "    \n",
    "soup = bs(html_str, \"html.parser\")\n",
    "        \n",
    "content = soup.find_all('a', class_=\"container__link container__link--type-article container_lead-plus-headlines__link container_lead-plus-headlines__left container_lead-plus-headlines__light\")\n",
    "\n",
    "for x in range(len(content)):\n",
    "    urls.append('https://edition.cnn.com'+content[x]['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa9527a-f5c2-4433-95a4-9bd1827c38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['urls'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3721c6b4-8ff5-48c6-a337-3d2e6b5934e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "nest_asyncio.apply()\n",
    "session = HTMLSession()\n",
    "\n",
    "for i in range(len(urls)):\n",
    "    r = session.get(urls[i])\n",
    "\n",
    "    html_str = r.text\n",
    "\n",
    "    soup = bs(html_str, \"html.parser\")\n",
    "    \n",
    "    content = soup.find_all(\"h1\", class_=\"headline__text inline-placeholder vossi-headline-primary-core-light\")\n",
    "    \n",
    "    for x in range(len(content)):\n",
    "        titles.append(content[x].text[16:])\n",
    "\n",
    "df['titles'] = titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43899c18-aecb-4e47-8e5b-94aab964bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_analysis_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb236eb-31ef-4630-8911-5e346393b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('sentiment_analysis_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96dcd5af-2105-49b3-a08c-a3740cf2156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "\n",
    "for i in df['titles']:\n",
    "    cleaned.append(clean_text(i.lower()))\n",
    "    \n",
    "df['cleaned_titles'] = cleaned\n",
    "\n",
    "df.to_csv(\"predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb80f5d-8596-437b-97f6-d4dfb3879de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df['cleaned_titles'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token= \"<OOV>\")\n",
    "tokenizer.fit_on_texts(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "770b5700-76d8-4dfe-a82b-0961f6e35521",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in df['cleaned_titles']:\n",
    "    title = [x.lower() for x in i]\n",
    "    t = [\" \".join(title)]\n",
    "    sequences = tokenizer.texts_to_sequences(t)\n",
    "    padded_seqs = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n",
    "    result = model.predict(padded_seqs)\n",
    "    predictions.append(round(result[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f85b714-f51b-4d17-9caf-5ec9d2e28637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['results'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d290de0c-30f4-4161-bdd9-64814305f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b383c-6eee-4ff4-9106-8e1b73efa2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
